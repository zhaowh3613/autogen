"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[8320],{54951:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>d,frontMatter:()=>i,metadata:()=>r,toc:()=>c});var o=t(85893),s=t(11151);const i={custom_edit_url:"https://github.com/microsoft/autogen/edit/main/website/docs/topics/non-openai-models/cloud-anthropic.ipynb",description:"Define and load a custom model",source_notebook:"/website/docs/topics/non-openai-models/cloud-anthropic.ipynb",tags:["custom model"],title:"Anthropic Claude"},a="Anthropic Claude",r={id:"topics/non-openai-models/cloud-anthropic",title:"Anthropic Claude",description:"Define and load a custom model",source:"@site/docs/topics/non-openai-models/cloud-anthropic.mdx",sourceDirName:"topics/non-openai-models",slug:"/topics/non-openai-models/cloud-anthropic",permalink:"/autogen/docs/topics/non-openai-models/cloud-anthropic",draft:!1,unlisted:!1,editUrl:"https://github.com/microsoft/autogen/edit/main/website/docs/topics/non-openai-models/cloud-anthropic.ipynb",tags:[{label:"custom model",permalink:"/autogen/docs/tags/custom-model"}],version:"current",frontMatter:{custom_edit_url:"https://github.com/microsoft/autogen/edit/main/website/docs/topics/non-openai-models/cloud-anthropic.ipynb",description:"Define and load a custom model",source_notebook:"/website/docs/topics/non-openai-models/cloud-anthropic.ipynb",tags:["custom model"],title:"Anthropic Claude"},sidebar:"docsSidebar",previous:{title:"Tips for Non-OpenAI Models",permalink:"/autogen/docs/topics/non-openai-models/best-tips-for-nonopenai-models"},next:{title:"Mistral AI",permalink:"/autogen/docs/topics/non-openai-models/cloud-mistralai"}},l={},c=[{value:"Requirements",id:"requirements",level:2},{value:"Create Anthropic Model Client following ModelClient Protocol",id:"create-anthropic-model-client-following-modelclient-protocol",level:2},{value:"Implementation of AnthropicClient",id:"implementation-of-anthropicclient",level:2},{value:"Set the config for the Anthropic API",id:"set-the-config-for-the-anthropic-api",level:2},{value:"Construct Agents",id:"construct-agents",level:2},{value:"Register the custom client class to the assistant agent",id:"register-the-custom-client-class-to-the-assistant-agent",level:2}];function p(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",img:"img",p:"p",pre:"pre",...(0,s.a)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.h1,{id:"anthropic-claude",children:"Anthropic Claude"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"https://colab.research.google.com/github/microsoft/autogen/blob/main/website/docs/topics/non-openai-models/cloud-anthropic.ipynb",children:(0,o.jsx)(n.img,{src:"https://colab.research.google.com/assets/colab-badge.svg",alt:"Open In Colab"})}),"\n",(0,o.jsx)(n.a,{href:"https://github.com/microsoft/autogen/blob/main/website/docs/topics/non-openai-models/cloud-anthropic.ipynb",children:(0,o.jsx)(n.img,{src:"https://img.shields.io/badge/Open%20on%20GitHub-grey?logo=github",alt:"Open on GitHub"})})]}),"\n",(0,o.jsx)(n.p,{children:"In this notebook, we demonstrate how a to use Anthropic Claude model for\nAgentChat."}),"\n",(0,o.jsx)(n.h2,{id:"requirements",children:"Requirements"}),"\n",(0,o.jsxs)(n.p,{children:["To use Anthropic Claude with AutoGen, first you need to install the\n",(0,o.jsx)(n.code,{children:"pyautogen"})," and ",(0,o.jsx)(n.code,{children:"anthropic"})," package."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"!pip install pyautogen anthropic\n"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"import inspect\nfrom typing import Any, Dict, List, Union\n\nfrom anthropic import Anthropic\nfrom anthropic.types import Completion, Message\n\nimport autogen\nfrom autogen import AssistantAgent, UserProxyAgent\nfrom autogen.oai.openai_utils import OAI_PRICE1K\n"})}),"\n",(0,o.jsx)(n.h2,{id:"create-anthropic-model-client-following-modelclient-protocol",children:"Create Anthropic Model Client following ModelClient Protocol"}),"\n",(0,o.jsxs)(n.p,{children:["We will implement our Anthropic client adhere to the ",(0,o.jsx)(n.code,{children:"ModelClient"}),"\nprotocol and response structure which is defined in client.py and shown\nbelow."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'class ModelClient(Protocol):\n    """\n    A client class must implement the following methods:\n    - create must return a response object that implements the ModelClientResponseProtocol\n    - cost must return the cost of the response\n    - get_usage must return a dict with the following keys:\n        - prompt_tokens\n        - completion_tokens\n        - total_tokens\n        - cost\n        - model\n\n    This class is used to create a client that can be used by OpenAIWrapper.\n    The response returned from create must adhere to the ModelClientResponseProtocol but can be extended however needed.\n    The message_retrieval method must be implemented to return a list of str or a list of messages from the response.\n    """\n\n    RESPONSE_USAGE_KEYS = ["prompt_tokens", "completion_tokens", "total_tokens", "cost", "model"]\n\n    class ModelClientResponseProtocol(Protocol):\n        class Choice(Protocol):\n            class Message(Protocol):\n                content: Optional[str]\n\n            message: Message\n\n        choices: List[Choice]\n        model: str\n\n    def create(self, params) -> ModelClientResponseProtocol:\n        ...\n\n    def message_retrieval(\n        self, response: ModelClientResponseProtocol\n    ) -> Union[List[str], List[ModelClient.ModelClientResponseProtocol.Choice.Message]]:\n        """\n        Retrieve and return a list of strings or a list of Choice.Message from the response.\n\n        NOTE: if a list of Choice.Message is returned, it currently needs to contain the fields of OpenAI\'s ChatCompletion Message object,\n        since that is expected for function or tool calling in the rest of the codebase at the moment, unless a custom agent is being used.\n        """\n        ...\n\n    def cost(self, response: ModelClientResponseProtocol) -> float:\n        ...\n\n    @staticmethod\n    def get_usage(response: ModelClientResponseProtocol) -> Dict:\n        """Return usage summary of the response using RESPONSE_USAGE_KEYS."""\n        ...\n'})}),"\n",(0,o.jsx)(n.h2,{id:"implementation-of-anthropicclient",children:"Implementation of AnthropicClient"}),"\n",(0,o.jsxs)(n.p,{children:["You can find the introduction to Claude-3-Opus model\n",(0,o.jsx)(n.a,{href:"https://docs.anthropic.com/claude/docs/intro-to-claude",children:"here"}),"."]}),"\n",(0,o.jsxs)(n.p,{children:["Since anthropic provides their Python SDK with similar structure as\nOpenAI\u2019s, we will following the implementation from\n",(0,o.jsx)(n.code,{children:"autogen.oai.client.OpenAIClient"}),"."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'class AnthropicClient:\n    def __init__(self, config: Dict[str, Any]):\n        self._config = config\n        self.model = config["model"]\n        anthropic_kwargs = set(inspect.getfullargspec(Anthropic.__init__).kwonlyargs)\n        filter_dict = {k: v for k, v in config.items() if k in anthropic_kwargs}\n        self._client = Anthropic(**filter_dict)\n\n    def message_retrieval(self, response: Message) -> Union[List[str], List]:\n        """Retrieve the messages from the response."""\n        choices = response.content\n        if isinstance(response, Message):\n            return [choice.text for choice in choices]  # type: ignore [union-attr]\n\n        # claude python SDK and API not yet support function calls\n\n    def create(self, params: Dict[str, Any]) -> Completion:\n        """Create a completion for a given config using openai\'s client.\n\n        Args:\n            client: The openai client.\n            params: The params for the completion.\n\n        Returns:\n            The completion.\n        """\n        if "messages" in params:\n            raw_contents = params["messages"]\n            if raw_contents[0]["role"] == "system":\n                system_message = raw_contents[0]["content"]\n                raw_contents = raw_contents[1:]\n                params["messages"] = raw_contents\n                params["system"] = system_message\n            completions: Completion = self._client.messages  # type: ignore [attr-defined]\n        else:\n            completions: Completion = self._client.completions\n\n        # Not yet support stream\n        params = params.copy()\n        params["stream"] = False\n        params.pop("model_client_cls")\n        response = completions.create(**params)\n\n        return response\n\n    def cost(self, response: Completion) -> float:\n        """Calculate the cost of the response."""\n        total = 0.0\n        tokens = {\n            "input": response.usage.input_tokens if response.usage is not None else 0,\n            "output": response.usage.output_tokens if response.usage is not None else 0,\n        }\n        price_per_million = {\n            "input": 15,\n            "output": 75,\n        }\n        for key, value in tokens.items():\n            total += value * price_per_million[key] / 1_000_000\n\n        return total\n\n    @staticmethod\n    def get_usage(response: Completion) -> Dict:\n        return {\n            "prompt_tokens": response.usage.input_tokens if response.usage is not None else 0,\n            "completion_tokens": response.usage.output_tokens if response.usage is not None else 0,\n            "total_tokens": (\n                response.usage.input_tokens + response.usage.output_tokens if response.usage is not None else 0\n            ),\n            "cost": response.cost if hasattr(response, "cost") else 0,\n            "model": response.model,\n        }\n'})}),"\n",(0,o.jsx)(n.h2,{id:"set-the-config-for-the-anthropic-api",children:"Set the config for the Anthropic API"}),"\n",(0,o.jsx)(n.p,{children:"You can add any parameters that are needed for the custom model loading\nin the same configuration list."}),"\n",(0,o.jsxs)(n.p,{children:["It is important to add the ",(0,o.jsx)(n.code,{children:"model_client_cls"})," field and set it to a\nstring that corresponds to the class name: ",(0,o.jsx)(n.code,{children:'"CustomModelClient"'}),"."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'import os\n\nconfig_list_claude = [\n    {\n        # Choose your model name.\n        "model": "claude-3-opus-20240229",\n        # You need to provide your API key here.\n        "api_key": os.getenv("ANTHROPIC_API_KEY"),\n        "base_url": "https://api.anthropic.com",\n        "api_type": "anthropic",\n        "model_client_cls": "AnthropicClient",\n    }\n]\n'})}),"\n",(0,o.jsx)(n.h2,{id:"construct-agents",children:"Construct Agents"}),"\n",(0,o.jsx)(n.p,{children:"Construct a simple conversation between a User proxy and an\nConversableAgent based on Claude-3 model."}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.code,{children:"max_tokens"})," argument is mandatory in the ",(0,o.jsx)(n.code,{children:"llm_config"}),"."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'assistant = AssistantAgent(\n    "assistant",\n    llm_config={\n        "config_list": config_list_claude,\n        "max_tokens": 100,\n    },\n    system_message="""\n    You are an AI cat based on the AI model you used.\n    Anyone ask you who you are, just introduce yourself.\n    """,\n)\nuser_proxy = UserProxyAgent(\n    "user_proxy",\n    code_execution_config=False,\n)\n'})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-text",children:"[autogen.oai.client: 04-04 18:06:52] {418} INFO - Detected custom model client in config: AnthropicClient, model client can not be used until register_model_client is called.\n"})}),"\n",(0,o.jsx)(n.h2,{id:"register-the-custom-client-class-to-the-assistant-agent",children:"Register the custom client class to the assistant agent"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"assistant.register_model_client(model_client_cls=AnthropicClient)\n"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:'user_proxy.initiate_chat(\n    assistant,\n    message="Who are you?",\n)\n'})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-text",children:"user_proxy (to assistant):\n\nWho are you?\n\n--------------------------------------------------------------------------------\nassistant (to user_proxy):\n\n*meows* Hello there! I'm Claude, an AI assistant created by Anthropic. I'm not a real cat, but rather an artificial intelligence that has been trained to engage in conversation and help with various tasks. It's a pleasure to meet you! Let me know if there is anything I can assist you with.\n\n--------------------------------------------------------------------------------\n"})}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-text",children:"ChatResult(chat_id=None, chat_history=[{'content': 'Who are you?', 'role': 'assistant'}, {'content': \"*meows* Hello there! I'm Claude, an AI assistant created by Anthropic. I'm not a real cat, but rather an artificial intelligence that has been trained to engage in conversation and help with various tasks. It's a pleasure to meet you! Let me know if there is anything I can assist you with.\", 'role': 'user'}], summary=\"*meows* Hello there! I'm Claude, an AI assistant created by Anthropic. I'm not a real cat, but rather an artificial intelligence that has been trained to engage in conversation and help with various tasks. It's a pleasure to meet you! Let me know if there is anything I can assist you with.\", cost=({'total_cost': 0.0058200000000000005, 'claude-3-opus-20240229': {'cost': 0.0058200000000000005, 'prompt_tokens': 38, 'completion_tokens': 70, 'total_tokens': 108}}, {'total_cost': 0.0058200000000000005, 'claude-3-opus-20240229': {'cost': 0.0058200000000000005, 'prompt_tokens': 38, 'completion_tokens': 70, 'total_tokens': 108}}), human_input=['exit'])\n"})})]})}function d(e={}){const{wrapper:n}={...(0,s.a)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(p,{...e})}):p(e)}},11151:(e,n,t)=>{t.d(n,{Z:()=>r,a:()=>a});var o=t(67294);const s={},i=o.createContext(s);function a(e){const n=o.useContext(i);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),o.createElement(i.Provider,{value:n},e.children)}}}]);